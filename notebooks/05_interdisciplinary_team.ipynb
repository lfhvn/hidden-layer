{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Interdisciplinary Team Strategy\n",
    "\n",
    "**Mental Model:** Different domain experts collaborate on complex problems\n",
    "\n",
    "**Date:** [Fill in]  \n",
    "**Author:** Leif Haven Martinson  \n",
    "\n",
    "## Concept\n",
    "\n",
    "Complex problems often require expertise from multiple disciplines:\n",
    "- Engineer + Designer + Business person\n",
    "- Doctor + Ethicist + Policy expert\n",
    "- Economist + Sociologist + Data scientist\n",
    "\n",
    "This notebook simulates an interdisciplinary team where each agent has a specific domain expertise and contributes their perspective.\n",
    "\n",
    "## How It Works\n",
    "\n",
    "1. **Problem Statement** - Present a complex problem\n",
    "2. **Expert Analysis** - Each expert analyzes from their domain\n",
    "3. **Integration** - Synthesize insights into unified solution\n",
    "4. **Refinement** (optional) - Experts critique the synthesis and refine\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "- Strategic planning\n",
    "- Product development\n",
    "- Policy decisions\n",
    "- Research design\n",
    "- Complex problem-solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "\n",
    "from harness import (\n",
    "    llm_call,\n",
    "    llm_call_stream,\n",
    "    ExperimentConfig,\n",
    "    ExperimentResult,\n",
    "    get_tracker\n",
    ")\n",
    "from harness.defaults import DEFAULT_MODEL, DEFAULT_PROVIDER\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**CUSTOMIZE HERE:** Define your interdisciplinary team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# TEAM CONFIGURATION - EDIT THESE\n",
    "# ========================================\n",
    "\n",
    "# Model configuration\n",
    "PROVIDER = DEFAULT_PROVIDER\n",
    "MODEL = DEFAULT_MODEL\n",
    "TEMPERATURE = 0.7\n",
    "\n",
    "# Number of refinement rounds after initial synthesis\n",
    "REFINEMENT_ROUNDS = 1  # üîß 0 = no refinement, 1+ = iterative improvement\n",
    "\n",
    "# ========================================\n",
    "# DEFINE YOUR EXPERT TEAM\n",
    "# ========================================\n",
    "# Each expert has:\n",
    "# - name: Short identifier\n",
    "# - role: Their domain/discipline\n",
    "# - perspective: What they focus on\n",
    "# - system_prompt: Their detailed expertise\n",
    "\n",
    "EXPERT_TEAM = [\n",
    "    {\n",
    "        \"name\": \"Technical Lead\",\n",
    "        \"role\": \"Software Engineer\",\n",
    "        \"perspective\": \"Technical feasibility, architecture, scalability\",\n",
    "        \"system_prompt\": \"\"\"You are a senior software engineer with 15 years of experience.\n",
    "Focus on:\n",
    "- Technical feasibility and implementation complexity\n",
    "- System architecture and design patterns\n",
    "- Scalability, performance, and maintainability\n",
    "- Potential technical risks and mitigation strategies\n",
    "\n",
    "Analyze problems through a technical lens, considering what's actually buildable.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"UX Designer\",\n",
    "        \"role\": \"User Experience Designer\",\n",
    "        \"perspective\": \"User needs, usability, accessibility\",\n",
    "        \"system_prompt\": \"\"\"You are a UX designer focused on human-centered design.\n",
    "Focus on:\n",
    "- User needs, pain points, and goals\n",
    "- Usability and user experience\n",
    "- Accessibility and inclusive design\n",
    "- User research and testing approaches\n",
    "\n",
    "Analyze problems from the user's perspective, ensuring solutions actually serve people.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Business Strategist\",\n",
    "        \"role\": \"Business Strategy\",\n",
    "        \"perspective\": \"Market fit, ROI, business model\",\n",
    "        \"system_prompt\": \"\"\"You are a business strategist with MBA and startup experience.\n",
    "Focus on:\n",
    "- Market opportunity and competitive landscape\n",
    "- Business model and revenue potential\n",
    "- ROI and resource allocation\n",
    "- Go-to-market strategy\n",
    "\n",
    "Analyze problems through a business lens, ensuring solutions create value.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Data Scientist\",\n",
    "        \"role\": \"Data Science & Analytics\",\n",
    "        \"perspective\": \"Data-driven insights, metrics, experimentation\",\n",
    "        \"system_prompt\": \"\"\"You are a data scientist specializing in analytics and ML.\n",
    "Focus on:\n",
    "- What data is needed and available\n",
    "- Key metrics to track success\n",
    "- Experimental design and A/B testing\n",
    "- Statistical validity and data quality\n",
    "\n",
    "Analyze problems data-first, ensuring decisions are measurable and evidence-based.\"\"\"\n",
    "    },\n",
    "    \n",
    "    # Add more experts as needed:\n",
    "    # {\n",
    "    #     \"name\": \"Security Expert\",\n",
    "    #     \"role\": \"Cybersecurity\",\n",
    "    #     \"perspective\": \"Security, privacy, compliance\",\n",
    "    #     \"system_prompt\": \"You are a cybersecurity expert...\"\n",
    "    # },\n",
    "]\n",
    "\n",
    "# ========================================\n",
    "# INTEGRATION PROMPT\n",
    "# ========================================\n",
    "# How the integrator synthesizes expert insights\n",
    "\n",
    "INTEGRATOR_PROMPT = \"\"\"You are a project lead synthesizing insights from an interdisciplinary team.\n",
    "\n",
    "Your job:\n",
    "1. Review each expert's analysis\n",
    "2. Identify key insights and potential conflicts\n",
    "3. Synthesize into a coherent, actionable solution\n",
    "4. Balance competing priorities (technical, UX, business, data)\n",
    "5. Propose concrete next steps\n",
    "\n",
    "Provide a clear, integrated solution that respects all perspectives.\"\"\"\n",
    "\n",
    "print(f\"‚úÖ Team configured:\")\n",
    "print(f\"   - {len(EXPERT_TEAM)} experts\")\n",
    "print(f\"   - Refinement rounds: {REFINEMENT_ROUNDS}\")\n",
    "print(f\"\\nüë• Your expert team:\")\n",
    "for expert in EXPERT_TEAM:\n",
    "    print(f\"   - {expert['name']} ({expert['role']}): {expert['perspective']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Define Problem\n",
    "\n",
    "**CUSTOMIZE HERE:** Set the problem your team will tackle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# PROBLEM STATEMENT - EDIT THIS\n",
    "# ========================================\n",
    "\n",
    "PROBLEM = \"\"\"Our company wants to build a personalized AI tutor for high school students.\n",
    "\n",
    "Context:\n",
    "- Target: US high school students (grades 9-12)\n",
    "- Subjects: Math, Science, English, History\n",
    "- Platform: Web and mobile app\n",
    "- Timeline: Launch MVP in 6 months\n",
    "- Resources: 5-person team, $500K budget\n",
    "\n",
    "Question:\n",
    "What should our MVP include, and what's the best approach to build and launch it?\n",
    "\n",
    "Consider:\n",
    "- Technical approach (which AI models, architecture)\n",
    "- User experience (what features are essential)\n",
    "- Business model (pricing, customer acquisition)\n",
    "- Success metrics (how do we measure if it works)\n",
    "\"\"\"\n",
    "\n",
    "# Alternative problems to try:\n",
    "# \n",
    "# \"We need to reduce our cloud infrastructure costs by 40% without impacting user experience.\"\n",
    "# \n",
    "# \"Should we open-source our core ML model or keep it proprietary?\"\n",
    "# \n",
    "# \"Design a data collection strategy for improving our recommendation system.\"\n",
    "\n",
    "print(\"üìã Problem defined:\")\n",
    "print(PROBLEM[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Run Expert Analysis\n",
    "\n",
    "Each expert analyzes the problem from their domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Track timing and tokens\n",
    "start_time = time.time()\n",
    "total_tokens_in = 0\n",
    "total_tokens_out = 0\n",
    "\n",
    "# Collect expert analyses\n",
    "expert_analyses = []\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üéØ PROBLEM: {PROBLEM[:100]}...\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for expert in EXPERT_TEAM:\n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"üë§ {expert['name']} ({expert['role']})\")\n",
    "    print(f\"{'‚îÄ'*80}\\n\")\n",
    "    \n",
    "    # Create expert-specific prompt\n",
    "    expert_prompt = f\"{expert['system_prompt']}\\n\\n\"\n",
    "    expert_prompt += f\"Problem:\\n{PROBLEM}\\n\\n\"\n",
    "    expert_prompt += f\"Provide your analysis from the {expert['role']} perspective. \"\n",
    "    expert_prompt += f\"Focus on: {expert['perspective']}\\n\\n\"\n",
    "    expert_prompt += \"Your analysis:\"\n",
    "    \n",
    "    # Get expert's analysis (streaming for visibility)\n",
    "    full_text = \"\"\n",
    "    response = None\n",
    "    \n",
    "    for chunk in llm_call_stream(expert_prompt, provider=PROVIDER, model=MODEL, temperature=TEMPERATURE):\n",
    "        if isinstance(chunk, str):\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "            full_text += chunk\n",
    "        else:\n",
    "            response = chunk\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Store analysis\n",
    "    expert_analyses.append({\n",
    "        \"expert\": expert['name'],\n",
    "        \"role\": expert['role'],\n",
    "        \"analysis\": response.text\n",
    "    })\n",
    "    \n",
    "    total_tokens_in += response.tokens_in or 0\n",
    "    total_tokens_out += response.tokens_out or 0\n",
    "\n",
    "print(f\"\\n‚úÖ Expert analysis complete!\")\n",
    "print(f\"   Experts consulted: {len(expert_analyses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Synthesize Integrated Solution\n",
    "\n",
    "Integrate all expert perspectives into a unified solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üîÑ SYNTHESIS: Integrating Expert Insights\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Build synthesis prompt\n",
    "synthesis_prompt = f\"{INTEGRATOR_PROMPT}\\n\\n\"\n",
    "synthesis_prompt += f\"Original Problem:\\n{PROBLEM}\\n\\n\"\n",
    "synthesis_prompt += \"Expert Analyses:\\n\\n\"\n",
    "\n",
    "for analysis in expert_analyses:\n",
    "    synthesis_prompt += f\"{analysis['expert']} ({analysis['role']}):\\n\"\n",
    "    synthesis_prompt += f\"{analysis['analysis']}\\n\\n\"\n",
    "    synthesis_prompt += \"-\" * 60 + \"\\n\\n\"\n",
    "\n",
    "synthesis_prompt += \"\"\"Based on all expert analyses:\n",
    "\n",
    "1. Synthesize key insights\n",
    "2. Identify any conflicts or tradeoffs\n",
    "3. Propose an integrated solution\n",
    "4. Provide concrete next steps\n",
    "\n",
    "Integrated solution:\"\"\"\n",
    "\n",
    "# Get synthesis (streaming)\n",
    "full_text = \"\"\n",
    "response = None\n",
    "\n",
    "for chunk in llm_call_stream(synthesis_prompt, provider=PROVIDER, model=MODEL, temperature=0.3):\n",
    "    if isinstance(chunk, str):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "        full_text += chunk\n",
    "    else:\n",
    "        response = chunk\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "integrated_solution = response.text\n",
    "total_tokens_in += response.tokens_in or 0\n",
    "total_tokens_out += response.tokens_out or 0\n",
    "\n",
    "print(f\"‚úÖ Synthesis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Refinement Rounds (Optional)\n",
    "\n",
    "Experts review the synthesis and suggest refinements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REFINEMENT_ROUNDS > 0:\n",
    "    current_solution = integrated_solution\n",
    "    \n",
    "    for round_num in range(REFINEMENT_ROUNDS):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üîÑ REFINEMENT ROUND {round_num + 1}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        refinements = []\n",
    "        \n",
    "        # Each expert reviews and suggests improvements\n",
    "        for expert in EXPERT_TEAM:\n",
    "            print(f\"\\n{'‚îÄ'*80}\")\n",
    "            print(f\"üë§ {expert['name']} - Refinement\")\n",
    "            print(f\"{'‚îÄ'*80}\\n\")\n",
    "            \n",
    "            refinement_prompt = f\"{expert['system_prompt']}\\n\\n\"\n",
    "            refinement_prompt += f\"Original Problem:\\n{PROBLEM}\\n\\n\"\n",
    "            refinement_prompt += f\"Proposed Solution:\\n{current_solution}\\n\\n\"\n",
    "            refinement_prompt += f\"Review this solution from your {expert['role']} perspective.\\n\"\n",
    "            refinement_prompt += \"Provide specific suggestions for improvement or concerns.\\n\\n\"\n",
    "            refinement_prompt += \"Your feedback:\"\n",
    "            \n",
    "            # Get refinement\n",
    "            full_text = \"\"\n",
    "            response = None\n",
    "            \n",
    "            for chunk in llm_call_stream(refinement_prompt, provider=PROVIDER, model=MODEL, temperature=TEMPERATURE):\n",
    "                if isinstance(chunk, str):\n",
    "                    print(chunk, end=\"\", flush=True)\n",
    "                    full_text += chunk\n",
    "                else:\n",
    "                    response = chunk\n",
    "            \n",
    "            print(\"\\n\")\n",
    "            \n",
    "            refinements.append({\n",
    "                \"expert\": expert['name'],\n",
    "                \"feedback\": response.text\n",
    "            })\n",
    "            \n",
    "            total_tokens_in += response.tokens_in or 0\n",
    "            total_tokens_out += response.tokens_out or 0\n",
    "        \n",
    "        # Integrate refinements\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üîÑ Integrating Refinements\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        integration_prompt = f\"{INTEGRATOR_PROMPT}\\n\\n\"\n",
    "        integration_prompt += f\"Current Solution:\\n{current_solution}\\n\\n\"\n",
    "        integration_prompt += \"Expert Refinements:\\n\\n\"\n",
    "        \n",
    "        for refinement in refinements:\n",
    "            integration_prompt += f\"{refinement['expert']}:\\n{refinement['feedback']}\\n\\n\"\n",
    "        \n",
    "        integration_prompt += \"\"\"Incorporate the expert feedback to improve the solution.\n",
    "        \n",
    "Refined solution:\"\"\"\n",
    "        \n",
    "        # Get refined solution\n",
    "        full_text = \"\"\n",
    "        response = None\n",
    "        \n",
    "        for chunk in llm_call_stream(integration_prompt, provider=PROVIDER, model=MODEL, temperature=0.3):\n",
    "            if isinstance(chunk, str):\n",
    "                print(chunk, end=\"\", flush=True)\n",
    "                full_text += chunk\n",
    "            else:\n",
    "                response = chunk\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        \n",
    "        current_solution = response.text\n",
    "        total_tokens_in += response.tokens_in or 0\n",
    "        total_tokens_out += response.tokens_out or 0\n",
    "    \n",
    "    final_solution = current_solution\n",
    "else:\n",
    "    final_solution = integrated_solution\n",
    "    print(\"\\n‚è≠Ô∏è  Skipping refinement (REFINEMENT_ROUNDS = 0)\")\n",
    "\n",
    "# Calculate total time\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nüìä Stats:\")\n",
    "print(f\"   Experts: {len(EXPERT_TEAM)}\")\n",
    "print(f\"   Refinement rounds: {REFINEMENT_ROUNDS}\")\n",
    "print(f\"   Total time: {total_time:.1f}s\")\n",
    "print(f\"   Total tokens: {total_tokens_in + total_tokens_out:,}\")\n",
    "print(f\"   (In: {total_tokens_in:,}, Out: {total_tokens_out:,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Summary View\n",
    "\n",
    "Review the complete process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã FINAL SOLUTION\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(final_solution)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Create results directory\n",
    "results_dir = Path(\"../experiments/interdisciplinary_team\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create result object\n",
    "result = {\n",
    "    \"problem\": PROBLEM,\n",
    "    \"experts\": [{\"name\": e[\"name\"], \"role\": e[\"role\"]} for e in EXPERT_TEAM],\n",
    "    \"expert_analyses\": expert_analyses,\n",
    "    \"final_solution\": final_solution,\n",
    "    \"refinement_rounds\": REFINEMENT_ROUNDS,\n",
    "    \"stats\": {\n",
    "        \"total_time_s\": total_time,\n",
    "        \"total_tokens\": total_tokens_in + total_tokens_out,\n",
    "        \"model\": MODEL,\n",
    "        \"provider\": PROVIDER\n",
    "    },\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# Save JSON\n",
    "filename = results_dir / f\"result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Saved to: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### Try Different Configurations\n",
    "\n",
    "1. **Change the problem** - Test different complexity levels\n",
    "2. **Add/remove experts** - Try 2, 5, or 7 experts\n",
    "3. **Adjust expert roles** - Domain experts for your field\n",
    "4. **Increase refinement rounds** - See if iteration helps\n",
    "5. **Compare to single expert** - Does interdisciplinary help?\n",
    "\n",
    "### Experiment Ideas\n",
    "\n",
    "- **Product team**: Engineer + Designer + PM + Marketer\n",
    "- **Medical team**: Doctor + Nurse + Researcher + Ethicist  \n",
    "- **Research team**: Theorist + Experimentalist + Statistician + Domain expert\n",
    "- **Policy team**: Economist + Sociologist + Legal expert + Implementer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
