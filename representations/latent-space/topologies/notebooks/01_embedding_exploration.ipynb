{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Latent Space Topologies - Embedding Exploration\n",
    "\n",
    "**Experiment:** Explore and visualize the geometry of embedding spaces\n",
    "\n",
    "**Date:** 2025-11-05\n",
    "\n",
    "**Research Question:** How can we understand and experience high-dimensional latent representations?\n",
    "\n",
    "**Goals:**\n",
    "- Load embedding model\n",
    "- Create embedding space from text corpus\n",
    "- Visualize topology and geometry\n",
    "- Identify concept clusters and boundaries\n",
    "- Prepare data for mobile app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# 1. Add repository root to path to import harness\nimport sys\nsys.path.append('../../../../')  # Go up to repo root from topologies/notebooks/\n\n# 2. Import standard libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 3. Import dimensionality reduction algorithms\nfrom sklearn.decomposition import PCA       # Principal Component Analysis\nfrom sklearn.manifold import TSNE            # t-SNE\nimport umap                                  # UMAP\n\n# 4. Import distance and clustering utilities\nfrom scipy.spatial.distance import pdist, squareform  # Distance calculations\nfrom scipy.cluster.hierarchy import linkage, dendrogram  # Hierarchical clustering\n\n# 5. Import harness experiment tracking\nfrom harness import ExperimentConfig, ExperimentResult, get_tracker\n\n# 6. Confirm successful imports\nprint(\"Imports successful\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Load Embedding Model\n",
    "\n",
    "Load a sentence embedding model (e.g., from sentence-transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    model_name = 'all-MiniLM-L6-v2'  # Lightweight model\n",
    "    embedding_model = SentenceTransformer(model_name)\n",
    "    \n",
    "    print(f\"Loaded model: {model_name}\")\n",
    "    print(f\"Embedding dimension: {embedding_model.get_sentence_embedding_dimension()}\")\n",
    "    use_embeddings = True\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"sentence-transformers not available\")\n",
    "    print(\"Install with: pip install sentence-transformers\")\n",
    "    use_embeddings = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Create Text Corpus\n",
    "\n",
    "Define a diverse set of concepts to embed and explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample corpus covering different semantic domains\n",
    "corpus = [\n",
    "    # Emotions\n",
    "    \"happiness\", \"sadness\", \"anger\", \"fear\", \"surprise\", \"disgust\", \"joy\", \"anxiety\",\n",
    "    \n",
    "    # Animals\n",
    "    \"dog\", \"cat\", \"bird\", \"fish\", \"elephant\", \"tiger\", \"whale\", \"butterfly\",\n",
    "    \n",
    "    # Colors\n",
    "    \"red\", \"blue\", \"green\", \"yellow\", \"orange\", \"purple\", \"black\", \"white\",\n",
    "    \n",
    "    # Abstract concepts\n",
    "    \"freedom\", \"justice\", \"truth\", \"beauty\", \"wisdom\", \"courage\", \"compassion\", \"creativity\",\n",
    "    \n",
    "    # Technology\n",
    "    \"computer\", \"internet\", \"artificial intelligence\", \"smartphone\", \"robot\", \"algorithm\", \"data\", \"network\",\n",
    "    \n",
    "    # Nature\n",
    "    \"mountain\", \"ocean\", \"forest\", \"desert\", \"river\", \"sun\", \"moon\", \"stars\",\n",
    "    \n",
    "    # Actions\n",
    "    \"running\", \"jumping\", \"thinking\", \"learning\", \"creating\", \"communicating\", \"exploring\", \"discovering\",\n",
    "]\n",
    "\n",
    "# Add labels for visualization\n",
    "labels = corpus.copy()\n",
    "\n",
    "print(f\"Corpus size: {len(corpus)} concepts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_embeddings:\n",
    "    # Encode corpus\n",
    "    embeddings = embedding_model.encode(corpus, show_progress_bar=True)\n",
    "    \n",
    "    print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "    print(f\"Embedding statistics:\")\n",
    "    print(f\"  Mean: {np.mean(embeddings):.4f}\")\n",
    "    print(f\"  Std: {np.std(embeddings):.4f}\")\n",
    "    print(f\"  Min: {np.min(embeddings):.4f}\")\n",
    "    print(f\"  Max: {np.max(embeddings):.4f}\")\n",
    "else:\n",
    "    # Use random embeddings for demonstration\n",
    "    embeddings = np.random.randn(len(corpus), 384)\n",
    "    print(\"Using synthetic embeddings for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Visualize with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D with PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d_pca = pca.fit_transform(embeddings)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.scatter(embeddings_2d_pca[:, 0], embeddings_2d_pca[:, 1], alpha=0.6, s=100)\n",
    "\n",
    "# Add labels\n",
    "for i, label in enumerate(labels):\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        (embeddings_2d_pca[i, 0], embeddings_2d_pca[i, 1]),\n",
    "        fontsize=9,\n",
    "        alpha=0.8,\n",
    "        xytext=(5, 5),\n",
    "        textcoords='offset points'\n",
    "    )\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('Concept Space Topology (PCA)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total variance explained: {sum(pca.explained_variance_ratio_):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Visualize with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D with t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=15, random_state=42)\n",
    "embeddings_2d_tsne = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.scatter(embeddings_2d_tsne[:, 0], embeddings_2d_tsne[:, 1], alpha=0.6, s=100)\n",
    "\n",
    "# Add labels\n",
    "for i, label in enumerate(labels):\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        (embeddings_2d_tsne[i, 0], embeddings_2d_tsne[i, 1]),\n",
    "        fontsize=9,\n",
    "        alpha=0.8,\n",
    "        xytext=(5, 5),\n",
    "        textcoords='offset points'\n",
    "    )\n",
    "\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.title('Concept Space Topology (t-SNE)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Visualize with UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D with UMAP\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "embeddings_2d_umap = reducer.fit_transform(embeddings)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.scatter(embeddings_2d_umap[:, 0], embeddings_2d_umap[:, 1], alpha=0.6, s=100)\n",
    "\n",
    "# Add labels\n",
    "for i, label in enumerate(labels):\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        (embeddings_2d_umap[i, 0], embeddings_2d_umap[i, 1]),\n",
    "        fontsize=9,\n",
    "        alpha=0.8,\n",
    "        xytext=(5, 5),\n",
    "        textcoords='offset points'\n",
    "    )\n",
    "\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.title('Concept Space Topology (UMAP)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 7. Compute Distance Matrix\n",
    "\n",
    "Analyze pairwise distances between concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(16, 14))\n",
    "plt.imshow(similarity_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.colorbar(label='Cosine Similarity')\n",
    "plt.xticks(range(len(labels)), labels, rotation=90, fontsize=8)\n",
    "plt.yticks(range(len(labels)), labels, fontsize=8)\n",
    "plt.title('Concept Similarity Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find most/least similar pairs\n",
    "n_concepts = len(labels)\n",
    "similarities = []\n",
    "for i in range(n_concepts):\n",
    "    for j in range(i+1, n_concepts):\n",
    "        similarities.append((labels[i], labels[j], similarity_matrix[i, j]))\n",
    "\n",
    "similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"\\nMost similar concept pairs:\")\n",
    "for i in range(min(5, len(similarities))):\n",
    "    print(f\"  {similarities[i][0]} <-> {similarities[i][1]}: {similarities[i][2]:.3f}\")\n",
    "\n",
    "print(\"\\nLeast similar concept pairs:\")\n",
    "for i in range(max(0, len(similarities)-5), len(similarities)):\n",
    "    print(f\"  {similarities[i][0]} <-> {similarities[i][1]}: {similarities[i][2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 8. Hierarchical Clustering\n",
    "\n",
    "Identify concept clusters and boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute linkage\n",
    "distances = pdist(embeddings, metric='cosine')\n",
    "linkage_matrix = linkage(distances, method='ward')\n",
    "\n",
    "# Plot dendrogram\n",
    "plt.figure(figsize=(16, 8))\n",
    "dendrogram(linkage_matrix, labels=labels, leaf_font_size=10)\n",
    "plt.xlabel('Concepts')\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Concept Hierarchy (Hierarchical Clustering)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 9. Export for Mobile App\n",
    "\n",
    "Prepare data for the Latent Topologies mobile application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Export concept constellation data\n",
    "constellation_data = {\n",
    "    'concepts': [\n",
    "        {\n",
    "            'id': i,\n",
    "            'label': labels[i],\n",
    "            'embedding': embeddings[i].tolist(),\n",
    "            'position_pca': embeddings_2d_pca[i].tolist(),\n",
    "            'position_tsne': embeddings_2d_tsne[i].tolist(),\n",
    "            'position_umap': embeddings_2d_umap[i].tolist(),\n",
    "        }\n",
    "        for i in range(len(labels))\n",
    "    ],\n",
    "    'metadata': {\n",
    "        'n_concepts': len(labels),\n",
    "        'embedding_dim': embeddings.shape[1],\n",
    "        'model': model_name if use_embeddings else 'synthetic',\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to data directory\n",
    "output_path = '../data/constellation_example.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(constellation_data, f, indent=2)\n",
    "\n",
    "print(f\"Exported constellation data to: {output_path}\")\n",
    "print(f\"  {len(labels)} concepts\")\n",
    "print(f\"  {embeddings.shape[1]}-dimensional embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 10. Track Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ExperimentConfig(\n",
    "    experiment_name=\"latent_topologies_embedding_exploration\",\n",
    "    task_type=\"embedding_analysis\",\n",
    "    strategy=\"dimensionality_reduction\",\n",
    "    provider=\"sentence_transformers\" if use_embeddings else \"synthetic\",\n",
    "    model=model_name if use_embeddings else \"random\",\n",
    ")\n",
    "\n",
    "tracker = get_tracker()\n",
    "run_dir = tracker.start_experiment(config)\n",
    "\n",
    "result = ExperimentResult(\n",
    "    config=config,\n",
    "    task_input=f\"Analyze {len(corpus)} concepts\",\n",
    "    output=f\"Created constellation with {len(labels)} concepts\",\n",
    "    eval_scores={},\n",
    "    eval_metadata={\n",
    "        'n_concepts': len(labels),\n",
    "        'embedding_dim': embeddings.shape[1],\n",
    "        'pca_variance': float(sum(pca.explained_variance_ratio_)),\n",
    "        'avg_similarity': float(np.mean(similarity_matrix[np.triu_indices_from(similarity_matrix, k=1)])),\n",
    "    },\n",
    "    success=True,\n",
    ")\n",
    "\n",
    "tracker.log_result(result)\n",
    "summary = tracker.finish_experiment()\n",
    "print(f\"Experiment logged in: {run_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "**Observations:**\n",
    "- Different dimensionality reduction methods reveal different aspects of topology\n",
    "- PCA preserves global structure but loses local relationships\n",
    "- t-SNE emphasizes local clusters\n",
    "- UMAP balances global and local structure\n",
    "- Semantic clusters emerge naturally (emotions, animals, colors, etc.)\n",
    "\n",
    "**Research Questions:**\n",
    "- How stable are these topologies across different models?\n",
    "- Can we navigate latent space intuitively on mobile?\n",
    "- What audio/haptic mappings best represent semantic distances?\n",
    "- How do concept boundaries shift with context?\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Mobile Integration**: Load constellation data into React Native app\n",
    "2. **Audio Mapping**: Design sound synthesis for semantic navigation\n",
    "3. **Haptic Feedback**: Map concept boundaries to vibration patterns\n",
    "4. **Interactive Annotation**: Allow users to reshape/annotate space\n",
    "\n",
    "## Mobile App Features\n",
    "\n",
    "Based on this exploration, the mobile app should:\n",
    "- Display concepts as a visual constellation\n",
    "- Allow touch navigation through semantic space\n",
    "- Provide audio feedback for semantic distance\n",
    "- Give haptic feedback when crossing concept boundaries\n",
    "- Support annotation and space manipulation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}