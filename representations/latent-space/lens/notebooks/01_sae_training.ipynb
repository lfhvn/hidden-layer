{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Sparse Autoencoder (SAE) Training\n",
    "\n",
    "**Experiment:** Train SAEs to discover interpretable features in model activations\n",
    "\n",
    "**Date:** 2025-11-05\n",
    "\n",
    "**Research Question:** What interpretable features emerge when we train sparse autoencoders on LLM activations?\n",
    "\n",
    "**Goals:**\n",
    "- Train SAE on model activations\n",
    "- Discover interpretable features\n",
    "- Analyze feature sparsity and quality\n",
    "- Export features for dashboard exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from harness import ExperimentConfig, ExperimentResult, get_tracker\n",
    "\n",
    "# Check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Define SAE Architecture\n",
    "\n",
    "Sparse Autoencoder with L1 regularization for feature sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, sparsity_weight=0.1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.sparsity_weight = sparsity_weight\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
    "        \n",
    "        # Initialize weights\n",
    "        nn.init.xavier_uniform_(self.encoder.weight)\n",
    "        nn.init.xavier_uniform_(self.decoder.weight)\n",
    "        nn.init.zeros_(self.encoder.bias)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        hidden = torch.relu(self.encoder(x))\n",
    "        \n",
    "        # Decode\n",
    "        reconstruction = self.decoder(hidden)\n",
    "        \n",
    "        return reconstruction, hidden\n",
    "    \n",
    "    def loss(self, x):\n",
    "        reconstruction, hidden = self.forward(x)\n",
    "        \n",
    "        # Reconstruction loss (MSE)\n",
    "        recon_loss = torch.mean((x - reconstruction) ** 2)\n",
    "        \n",
    "        # Sparsity loss (L1 on hidden activations)\n",
    "        sparsity_loss = torch.mean(torch.abs(hidden))\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss = recon_loss + self.sparsity_weight * sparsity_loss\n",
    "        \n",
    "        return total_loss, recon_loss, sparsity_loss\n",
    "\n",
    "print(\"SAE architecture defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Generate Training Data\n",
    "\n",
    "Collect activations from a model to train the SAE\n",
    "\n",
    "Note: In production, this would load real model activations. For demonstration, we'll use synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace with real activation collection\n",
    "# For now, generate synthetic data\n",
    "\n",
    "def generate_synthetic_activations(n_samples=10000, activation_dim=768, n_features=100, sparsity=0.1):\n",
    "    \"\"\"\n",
    "    Generate synthetic activations with sparse underlying features.\n",
    "    \n",
    "    Real implementation would:\n",
    "    1. Load a model (e.g., via MLX or transformers)\n",
    "    2. Pass text through and capture layer activations\n",
    "    3. Store activations for SAE training\n",
    "    \"\"\"\n",
    "    # Create sparse feature matrix\n",
    "    features = torch.zeros((n_samples, n_features))\n",
    "    for i in range(n_samples):\n",
    "        # Activate a few random features\n",
    "        active_features = torch.randperm(n_features)[:int(n_features * sparsity)]\n",
    "        features[i, active_features] = torch.randn(len(active_features)).abs()\n",
    "    \n",
    "    # Project to activation space\n",
    "    projection = torch.randn((n_features, activation_dim))\n",
    "    activations = features @ projection\n",
    "    \n",
    "    # Add noise\n",
    "    activations += torch.randn_like(activations) * 0.1\n",
    "    \n",
    "    return activations\n",
    "\n",
    "# Generate training data\n",
    "activation_dim = 768  # e.g., hidden size of model\n",
    "n_train_samples = 10000\n",
    "n_val_samples = 1000\n",
    "\n",
    "train_activations = generate_synthetic_activations(n_train_samples, activation_dim)\n",
    "val_activations = generate_synthetic_activations(n_val_samples, activation_dim)\n",
    "\n",
    "print(f\"Training data shape: {train_activations.shape}\")\n",
    "print(f\"Validation data shape: {val_activations.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Train SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_dim = 2048  # Typically larger than input for overcomplete representation\n",
    "sparsity_weight = 0.05\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3\n",
    "n_epochs = 20\n",
    "\n",
    "# Create model\n",
    "sae = SparseAutoencoder(\n",
    "    input_dim=activation_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    sparsity_weight=sparsity_weight,\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(sae.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(train_activations),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    TensorDataset(val_activations),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(f\"Training SAE ({hidden_dim} features)...\\n\")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    sae.train()\n",
    "    epoch_loss = 0\n",
    "    for (batch,) in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss, recon_loss, sparsity_loss = sae.loss(batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    train_losses.append(epoch_loss / len(train_loader))\n",
    "    \n",
    "    # Validation\n",
    "    sae.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for (batch,) in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            loss, _, _ = sae.loss(batch)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "        print(f\"  Train Loss: {train_losses[-1]:.4f}\")\n",
    "        print(f\"  Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Analyze Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('SAE Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Analyze Feature Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure feature activation sparsity\n",
    "sae.eval()\n",
    "with torch.no_grad():\n",
    "    sample_batch = val_activations[:1000].to(device)\n",
    "    _, features = sae(sample_batch)\n",
    "    features = features.cpu().numpy()\n",
    "\n",
    "# Compute sparsity metrics\n",
    "feature_means = np.mean(features, axis=0)\n",
    "feature_activation_freq = np.mean(features > 0, axis=0)\n",
    "\n",
    "print(f\"Feature statistics:\")\n",
    "print(f\"  Mean activation: {np.mean(feature_means):.4f}\")\n",
    "print(f\"  Std activation: {np.std(feature_means):.4f}\")\n",
    "print(f\"  Average sparsity: {np.mean(feature_activation_freq):.2%}\")\n",
    "print(f\"  Features active >1%: {np.sum(feature_activation_freq > 0.01)}\")\n",
    "\n",
    "# Plot feature activation histogram\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(feature_activation_freq, bins=50)\n",
    "plt.xlabel('Activation Frequency')\n",
    "plt.ylabel('Number of Features')\n",
    "plt.title('Feature Activation Frequency Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(feature_means, bins=50)\n",
    "plt.xlabel('Mean Activation')\n",
    "plt.ylabel('Number of Features')\n",
    "plt.title('Feature Mean Activation Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Export for Dashboard\n",
    "\n",
    "Save trained SAE for exploration in the Lens dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "save_path = \"../models/sae_example.pt\"\n",
    "torch.save({\n",
    "    'model_state_dict': sae.state_dict(),\n",
    "    'config': {\n",
    "        'input_dim': activation_dim,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'sparsity_weight': sparsity_weight,\n",
    "    },\n",
    "    'training_config': {\n",
    "        'n_epochs': n_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate,\n",
    "    },\n",
    "    'metrics': {\n",
    "        'final_train_loss': train_losses[-1],\n",
    "        'final_val_loss': val_losses[-1],\n",
    "        'avg_sparsity': float(np.mean(feature_activation_freq)),\n",
    "    },\n",
    "}, save_path)\n",
    "\n",
    "print(f\"Saved SAE to: {save_path}\")\n",
    "\n",
    "# Export feature metadata\n",
    "import json\n",
    "\n",
    "metadata = {\n",
    "    'n_features': hidden_dim,\n",
    "    'activation_dim': activation_dim,\n",
    "    'avg_sparsity': float(np.mean(feature_activation_freq)),\n",
    "    'active_features': int(np.sum(feature_activation_freq > 0.01)),\n",
    "}\n",
    "\n",
    "with open('../models/sae_example_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"Exported metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 7. Track Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ExperimentConfig(\n",
    "    experiment_name=\"sae_training\",\n",
    "    task_type=\"feature_discovery\",\n",
    "    strategy=\"sparse_autoencoder\",\n",
    "    provider=\"local\",\n",
    "    model=\"sae\",\n",
    ")\n",
    "\n",
    "tracker = get_tracker()\n",
    "run_dir = tracker.start_experiment(config)\n",
    "\n",
    "result = ExperimentResult(\n",
    "    config=config,\n",
    "    task_input=f\"Train SAE on {n_train_samples} activations\",\n",
    "    output=f\"Trained {hidden_dim}-feature SAE\",\n",
    "    eval_scores={\n",
    "        'final_train_loss': train_losses[-1],\n",
    "        'final_val_loss': val_losses[-1],\n",
    "        'avg_sparsity': float(np.mean(feature_activation_freq)),\n",
    "    },\n",
    "    eval_metadata={\n",
    "        'n_features': hidden_dim,\n",
    "        'activation_dim': activation_dim,\n",
    "        'sparsity_weight': sparsity_weight,\n",
    "        'n_epochs': n_epochs,\n",
    "    },\n",
    "    success=True,\n",
    ")\n",
    "\n",
    "tracker.log_result(result)\n",
    "summary = tracker.finish_experiment()\n",
    "print(f\"Experiment logged in: {run_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Feature Analysis** (02_feature_analysis.ipynb): Analyze what concepts each feature represents\n",
    "2. **Feature Steering** (03_feature_steering.ipynb): Use features to steer model behavior\n",
    "3. **Dashboard Exploration**: Load SAE into Lens dashboard for interactive exploration\n",
    "\n",
    "## Key Research Questions\n",
    "\n",
    "- What semantic concepts do individual features capture?\n",
    "- How do features compose to represent complex concepts?\n",
    "- Do features align with human-interpretable concepts?\n",
    "- Can we steer models via feature activation?\n",
    "- How do features differ across layers?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
