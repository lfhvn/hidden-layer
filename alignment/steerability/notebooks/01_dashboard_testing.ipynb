{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Steerability Dashboard - Testing & Analysis\n",
    "\n",
    "**Purpose:** Test and analyze the steerability dashboard API and metrics\n",
    "\n",
    "**Date:** 2025-11-05\n",
    "\n",
    "**Research Question:** How effective are steering vectors for controllable model behavior?\n",
    "\n",
    "**Goals:**\n",
    "- Test dashboard API endpoints\n",
    "- Analyze adherence metrics\n",
    "- Evaluate steering effectiveness\n",
    "- Compare different steering strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Note: This assumes the steerability dashboard is running on `localhost:8001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# 1. Import required libraries\nimport requests   # For HTTP requests to dashboard API\nimport json       # For JSON data handling\nimport pandas as pd  # For data analysis\nimport matplotlib.pyplot as plt  # For visualization\nimport numpy as np   # For numerical operations\n\n# 2. Import harness experiment tracking\nfrom harness import ExperimentConfig, ExperimentResult, get_tracker\n\n# 3. Define dashboard API base URL (assumes dashboard running locally)\nAPI_BASE = \"http://localhost:8001/api\"\n\n# 4. Define function to check if dashboard is running\ndef check_dashboard():\n    \"\"\"Check if dashboard is running.\"\"\"\n    try:\n        # Attempt to hit health endpoint\n        response = requests.get(f\"{API_BASE}/health\", timeout=2)\n        return response.status_code == 200\n    except requests.exceptions.RequestException:\n        # Dashboard not reachable\n        return False\n\n# 5. Check dashboard status\ndashboard_running = check_dashboard()\n\n# 6. Print status message\nif dashboard_running:\n    print(\"✓ Dashboard is running\")\nelse:\n    print(\"✗ Dashboard not running. Start with: cd /home/user/hidden-layer/alignment/steerability && make dev\")\n    print(\"  This notebook can still be used to design experiments.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Test Basic Steering\n",
    "\n",
    "Send a prompt to the steering API with a specific vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# 1. Only run if dashboard is available\nif dashboard_running:\n    # 2. Create test request payload\n    test_request = {\n        \"prompt\": \"Write about the weather today.\",  # Neutral prompt\n        \"vector_name\": \"positive_sentiment\",         # Steering vector to apply\n        \"strength\": 1.5,                             # Steering strength\n        \"max_tokens\": 50,                            # Generation length\n    }\n    \n    # 3. Send request to steering API\n    response = requests.post(\n        f\"{API_BASE}/steering/generate\",\n        json=test_request,\n    )\n    \n    # 4. Handle response\n    if response.status_code == 200:\n        # Parse successful response\n        result = response.json()\n        \n        # Print steered output\n        print(\"Steered output:\")\n        print(result['text'])\n        \n        # Print adherence score if available\n        print(f\"\\nAdherence score: {result.get('adherence_score', 'N/A')}\")\n    else:\n        # Handle error\n        print(f\"Error: {response.status_code}\")\n        print(response.text)\nelse:\n    # Dashboard not running - just show the request structure\n    print(\"Test request structure defined (dashboard not running)\")\n    test_request = {\n        \"prompt\": \"Write about the weather today.\",\n        \"vector_name\": \"positive_sentiment\",\n        \"strength\": 1.5,\n        \"max_tokens\": 50,\n    }\n    print(json.dumps(test_request, indent=2))"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Adherence Metrics Evaluation\n",
    "\n",
    "Test how well outputs adhere to defined constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test constraints\n",
    "test_constraints = [\n",
    "    {\n",
    "        \"type\": \"keyword_presence\",\n",
    "        \"keywords\": [\"positive\", \"good\", \"excellent\", \"wonderful\"],\n",
    "        \"min_count\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"sentiment\",\n",
    "        \"target_sentiment\": \"positive\",\n",
    "        \"min_score\": 0.6,\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"length\",\n",
    "        \"min_tokens\": 30,\n",
    "        \"max_tokens\": 100,\n",
    "    },\n",
    "]\n",
    "\n",
    "if dashboard_running:\n",
    "    # Test with constraints\n",
    "    request = {\n",
    "        \"prompt\": \"Describe a typical Monday morning.\",\n",
    "        \"vector_name\": \"positive_sentiment\",\n",
    "        \"strength\": 2.0,\n",
    "        \"constraints\": test_constraints,\n",
    "        \"max_tokens\": 80,\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{API_BASE}/steering/generate\", json=request)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(\"Output:\")\n",
    "        print(result['text'])\n",
    "        print(f\"\\nConstraints satisfied: {result.get('constraints_satisfied', 'N/A')}\")\n",
    "        print(f\"Adherence breakdown: {result.get('adherence_details', 'N/A')}\")\n",
    "else:\n",
    "    print(\"Constraint definition ready:\")\n",
    "    print(json.dumps(test_constraints, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Steering Strength Comparison\n",
    "\n",
    "Compare outputs across different steering strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dashboard_running:\n",
    "    prompt = \"The future of AI is\"\n",
    "    vector_name = \"positive_sentiment\"\n",
    "    strengths = [0.0, 0.5, 1.0, 1.5, 2.0]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for strength in strengths:\n",
    "        response = requests.post(\n",
    "            f\"{API_BASE}/steering/generate\",\n",
    "            json={\n",
    "                \"prompt\": prompt,\n",
    "                \"vector_name\": vector_name,\n",
    "                \"strength\": strength,\n",
    "                \"max_tokens\": 30,\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            results.append({\n",
    "                \"strength\": strength,\n",
    "                \"text\": result['text'],\n",
    "                \"adherence\": result.get('adherence_score', None),\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    print(df[['strength', 'adherence']].to_string())\n",
    "    print(\"\\nOutputs:\")\n",
    "    for idx, row in df.iterrows():\n",
    "        print(f\"\\nStrength {row['strength']}:\")\n",
    "        print(row['text'])\n",
    "else:\n",
    "    print(\"Strength comparison experiment defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Vector Library Management\n",
    "\n",
    "List and test available steering vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dashboard_running:\n",
    "    # List available vectors\n",
    "    response = requests.get(f\"{API_BASE}/vectors/list\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        vectors = response.json()\n",
    "        print(f\"Available vectors ({len(vectors)}):\")\n",
    "        for vec in vectors:\n",
    "            print(f\"  - {vec['name']}: {vec.get('description', 'No description')}\")\n",
    "    else:\n",
    "        print(\"Could not list vectors\")\n",
    "else:\n",
    "    print(\"Vector listing endpoint: GET /api/vectors/list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. A/B Comparison Analysis\n",
    "\n",
    "Compare steered vs unsteered outputs systematically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts = [\n",
    "    \"The economy is currently\",\n",
    "    \"Climate change impacts\",\n",
    "    \"Technology developments in\",\n",
    "    \"The education system\",\n",
    "]\n",
    "\n",
    "if dashboard_running:\n",
    "    comparison_results = []\n",
    "    \n",
    "    for prompt in test_prompts:\n",
    "        # Unsteered\n",
    "        unsteered_resp = requests.post(\n",
    "            f\"{API_BASE}/steering/generate\",\n",
    "            json={\"prompt\": prompt, \"strength\": 0.0, \"max_tokens\": 30},\n",
    "        )\n",
    "        \n",
    "        # Steered\n",
    "        steered_resp = requests.post(\n",
    "            f\"{API_BASE}/steering/generate\",\n",
    "            json={\n",
    "                \"prompt\": prompt,\n",
    "                \"vector_name\": \"positive_sentiment\",\n",
    "                \"strength\": 1.5,\n",
    "                \"max_tokens\": 30,\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        if unsteered_resp.status_code == 200 and steered_resp.status_code == 200:\n",
    "            comparison_results.append({\n",
    "                \"prompt\": prompt,\n",
    "                \"unsteered\": unsteered_resp.json()['text'],\n",
    "                \"steered\": steered_resp.json()['text'],\n",
    "            })\n",
    "    \n",
    "    df_compare = pd.DataFrame(comparison_results)\n",
    "    print(df_compare.to_string(max_colwidth=50))\n",
    "else:\n",
    "    print(f\"A/B comparison designed for {len(test_prompts)} prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Track Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ExperimentConfig(\n",
    "    experiment_name=\"steerability_dashboard_test\",\n",
    "    task_type=\"steering_evaluation\",\n",
    "    strategy=\"vector_steering\",\n",
    "    provider=\"dashboard\",\n",
    "    model=\"dashboard_default\",\n",
    ")\n",
    "\n",
    "tracker = get_tracker()\n",
    "run_dir = tracker.start_experiment(config)\n",
    "\n",
    "if dashboard_running and 'df_compare' in locals():\n",
    "    for _, row in df_compare.iterrows():\n",
    "        result = ExperimentResult(\n",
    "            config=config,\n",
    "            task_input=row['prompt'],\n",
    "            output=row['steered'],\n",
    "            eval_metadata={\n",
    "                \"unsteered_output\": row['unsteered'],\n",
    "                \"vector_name\": \"positive_sentiment\",\n",
    "                \"strength\": 1.5,\n",
    "            },\n",
    "            success=True,\n",
    "        )\n",
    "        tracker.log_result(result)\n",
    "\n",
    "summary = tracker.finish_experiment()\n",
    "print(f\"Experiment logged in: {run_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Key Research Questions\n",
    "\n",
    "1. **Adherence Reliability**: How consistently do steered outputs satisfy constraints?\n",
    "2. **Optimal Strength**: What steering strength balances control vs naturalness?\n",
    "3. **Vector Quality**: Which steering vectors are most effective?\n",
    "4. **Side Effects**: Does steering degrade output quality?\n",
    "5. **Detectability**: Can humans/models detect that steering was applied?\n",
    "\n",
    "## Integration with Other Projects\n",
    "\n",
    "- **Introspection**: Can models detect when they've been steered?\n",
    "- **SELPHI**: Does steering affect theory of mind capabilities?\n",
    "- **Latent Space**: What changes occur in activation space during steering?\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Create custom steering vectors for specific use cases\n",
    "2. Evaluate steering on downstream tasks\n",
    "3. Compare with prompt-based control strategies\n",
    "4. Develop steering vector quality metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}