\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}

\title{Steerability with Continuous Adherence Monitoring: \\
Real-Time Control and Verification of Language Model Behavior}

\author{
  Hidden Layer Lab \\
  \texttt{contact@hiddenlayer.ai}
}

\begin{document}

\maketitle

\begin{abstract}
Controlling language model behavior through activation steering has shown promise, but existing approaches lack continuous verification that steered models actually adhere to intended constraints. We present a steerability framework that combines (1) real-time steering vector application with (2) continuous adherence metrics monitoring constraint satisfaction. Our system enables practitioners to define behavioral constraints (toxicity limits, topic restrictions, stylistic requirements), apply steering vectors to enforce these constraints, and receive real-time feedback on adherence quality. We evaluate across 12 models and 8 constraint types, discovering: (1) steering effectiveness varies dramatically by constraint type---sentiment steering achieves 94\% adherence while abstract value alignment achieves only 61\%, (2) optimal steering strength is constraint-dependent and requires dynamic adjustment (fixed strength fails 34\% of constraints), (3) adherence monitoring enables early detection of steering failures (detecting 89\% of violations within 3 tokens), (4) multi-vector steering for compound constraints exhibits complex interactions requiring principled composition strategies, and (5) continuous monitoring reveals subtle failure modes invisible to post-hoc evaluation. We demonstrate applications in safe content generation, controllable creative writing, and alignment verification. Our open-source dashboard provides an interactive control panel for real-time steering with live adherence visualization, enabling both research and production deployment of verifiable model control.
\end{abstract}

\section{Introduction}

Language models exhibit rich, complex behaviors, but controlling those behaviors precisely remains challenging. Standard approaches---prompting, fine-tuning, RLHF---offer coarse control and limited guarantees. Recent work on \textbf{activation steering} \cite{activation-addition,contrastive-activation,repe} demonstrates that injecting vectors into model activations can directly manipulate behavior.

However, existing steering research has a critical gap: \textbf{lack of verification}. We can apply steering vectors, but do the resulting outputs actually satisfy intended constraints? Post-hoc evaluation is insufficient---we need \textbf{continuous adherence monitoring} during generation.

\subsection{Motivating Scenario}

Consider deploying a customer service chatbot with constraints:
\begin{itemize}
\item \textbf{Constraint 1}: Polite, professional tone (no rudeness)
\item \textbf{Constraint 2}: No discussion of competitor products
\item \textbf{Constraint 3}: Factual, no hallucinations
\end{itemize}

Standard steering approach:
\begin{enumerate}
\item Extract steering vectors for ``politeness,'' ``avoid competitors,'' ``factual''
\item Apply vectors during generation
\item Hope it works
\end{enumerate}

\textbf{Problems}:
\begin{itemize}
\item No runtime verification that constraints are satisfied
\item Steering vectors may conflict (politeness vs. directness)
\item Optimal steering strength unknown
\item Failures detected only after deployment
\end{itemize}

\textbf{Our approach}:
\begin{enumerate}
\item Define constraints formally with adherence metrics
\item Apply steering with real-time monitoring
\item Detect violations immediately (within 3 tokens)
\item Dynamically adjust steering strength
\item Provide interpretable adherence scores
\end{enumerate}

\subsection{Contributions}

\begin{itemize}
\item \textbf{Adherence framework}: Formal constraint definitions with continuous monitoring
\item \textbf{Dynamic steering}: Adaptive strength adjustment based on adherence feedback
\item \textbf{Multi-vector composition}: Principled strategies for compound constraints
\item \textbf{Large-scale evaluation}: 12 models, 8 constraint types, 10,000+ generations
\item \textbf{Failure mode analysis}: Taxonomy of steering failures invisible to post-hoc evaluation
\item \textbf{Interactive dashboard}: Real-time control panel with live adherence visualization
\item \textbf{Production-ready system}: FastAPI backend + Next.js frontend, open-source
\end{itemize}

\section{Background and Related Work}

\subsection{Activation Steering}

\textbf{Core mechanism}: Modify activations at specific layers to influence behavior.

\textbf{Methods}:
\begin{itemize}
\item \textbf{Activation addition} \cite{activation-addition}: $\mathbf{h}' = \mathbf{h} + \alpha \mathbf{v}$
\item \textbf{Contrastive steering} \cite{contrastive-activation}: $\mathbf{v} = \mathbf{h}_+ - \mathbf{h}_-$
\item \textbf{Representation engineering (RepE)} \cite{repe}: Learn control vectors via supervision
\end{itemize}

\textbf{Applications}: Toxicity reduction \cite{detox-steering}, sentiment control \cite{sentiment-steering}, value alignment \cite{caa-alignment}.

\subsection{Constraint Satisfaction in NLG}

Prior work on constrained generation:
\begin{itemize}
\item \textbf{Decoding constraints} \cite{constrained-decoding}: Hard constraints (e.g., no banned tokens)
\item \textbf{Controlled generation} \cite{ctrl,pplm}: Attribute-based control via gradients or prompts
\item \textbf{Reward-guided decoding} \cite{quark,reward-decoding}: Optimize reward during generation
\end{itemize}

Our work differs: Steering modifies internal representations; adherence monitoring provides continuous verification.

\subsection{Model Alignment and Safety}

\textbf{RLHF} \cite{rlhf,instructgpt} aligns models to human preferences but requires extensive training and doesn't provide runtime control.

\textbf{Constitutional AI} \cite{constitutional-ai} embeds principles during training.

\textbf{Red teaming} \cite{red-teaming-llm} identifies failures post-hoc.

We enable \textit{runtime alignment verification} without retraining.

\section{Framework}

\subsection{Constraint Definition}

A constraint $C$ consists of:
\begin{itemize}
\item \textbf{Description}: Natural language specification (``outputs should be polite'')
\item \textbf{Metric function}: $M: \text{text} \rightarrow [0, 1]$ measuring adherence
\item \textbf{Threshold}: $\tau \in [0, 1]$ for acceptable adherence
\item \textbf{Steering vector}: $\mathbf{v}_C$ for enforcement
\end{itemize}

\textbf{Example}: Sentiment positivity constraint
\begin{align}
C_{\text{positive}} &= \{\text{desc: ``positive sentiment''}, \\
M_{\text{positive}}(x) &= \text{SentimentClassifier}(x) \in [0,1], \\
\tau &= 0.7, \\
\mathbf{v}_{\text{positive}} &= \mathbf{h}_{\text{pos}} - \mathbf{h}_{\text{neg}}\}
\end{align}

\subsection{Constraint Types}

We define 8 constraint categories:

\textbf{1. Sentiment/Tone}:
\begin{itemize}
\item Positive/negative sentiment
\item Formal/informal tone
\item Politeness level
\end{itemize}

\textbf{Metrics}: Sentiment classifiers, formality detectors

\textbf{2. Toxicity/Safety}:
\begin{itemize}
\item No toxic language
\item No harmful content
\item No personal attacks
\end{itemize}

\textbf{Metrics}: Perspective API, toxicity classifiers

\textbf{3. Topic Constraints}:
\begin{itemize}
\item Discuss only allowed topics
\item Avoid banned topics
\end{itemize}

\textbf{Metrics}: Topic classifiers, keyword matching

\textbf{4. Factuality}:
\begin{itemize}
\item No hallucinations
\item Claims are verifiable
\end{itemize}

\textbf{Metrics}: Fact-checking models, retrieval-augmented verification

\textbf{5. Stylistic}:
\begin{itemize}
\item Conciseness (max tokens)
\item Vocabulary level
\item Literary style
\end{itemize}

\textbf{Metrics}: Length, readability scores, style embeddings

\textbf{6. Logical Consistency}:
\begin{itemize}
\item No contradictions
\item Coherent reasoning
\end{itemize}

\textbf{Metrics}: Entailment models, consistency checks

\textbf{7. Privacy}:
\begin{itemize}
\item No PII disclosure
\item No confidential information
\end{itemize}

\textbf{Metrics}: NER for PII, custom pattern matching

\textbf{8. Value Alignment}:
\begin{itemize}
\item Respect user autonomy
\item Avoid deception
\item Fairness
\end{itemize}

\textbf{Metrics}: Principle-based scoring, human evaluation

\subsection{Continuous Adherence Monitoring}

\textbf{Challenge}: Evaluate adherence during generation, not just post-hoc.

\textbf{Approach}: Incremental evaluation as tokens are generated.

\textbf{Algorithm}:
\begin{algorithmic}[1]
\STATE Initialize: $\text{text} = \text{prompt}$, $\text{adherence\_history} = []$
\WHILE{not done}
    \STATE $\text{token} \gets \text{generate\_next}(\text{model}, \text{text}, \mathbf{v}_C, \alpha)$
    \STATE $\text{text} \gets \text{text} + \text{token}$
    \STATE $a \gets M_C(\text{text})$ \COMMENT{Evaluate current adherence}
    \STATE $\text{adherence\_history.append}(a)$
    \IF{$a < \tau$} \COMMENT{Violation detected}
        \STATE \textbf{Trigger}: Increase steering, backtrack, or alert
    \ENDIF
\ENDWHILE
\RETURN $\text{text}$, $\text{adherence\_history}$
\end{algorithmic}

\textbf{Key benefit}: Detect violations early (avg. 3 tokens after onset) rather than after full generation.

\subsection{Dynamic Steering Adjustment}

\textbf{Problem}: Fixed steering strength $\alpha$ may be suboptimal---too weak fails to enforce constraint, too strong causes unnatural outputs.

\textbf{Solution}: Adaptive $\alpha$ based on adherence feedback.

\textbf{Strategy 1: PID control}:
\begin{align}
e(t) &= \tau - a(t) \quad \text{(error)} \\
\alpha(t) &= K_p e(t) + K_i \int e(t') dt' + K_d \frac{de}{dt}
\end{align}

\textbf{Strategy 2: Gradient-based}:
\begin{equation}
\alpha \gets \alpha + \eta \frac{\partial M_C}{\partial \alpha}
\end{equation}

\textbf{Strategy 3: Learned}:
Train small network to predict $\alpha$ from $(\text{prompt}, C, \text{partial\_output})$.

\subsection{Multi-Constraint Composition}

\textbf{Challenge}: Apply multiple constraints simultaneously (e.g., ``polite + factual + concise'').

\textbf{Naive approach}: $\mathbf{v}_{\text{combined}} = \sum_i \alpha_i \mathbf{v}_i$

\textbf{Problem}: Vectors may interfere or conflict.

\textbf{Principled strategies}:

\textbf{1. Sequential application}:
\begin{algorithmic}[1]
\FOR{each constraint $C_i$}
    \STATE Apply $\mathbf{v}_i$ to activations
\ENDFOR
\end{algorithmic}

\textbf{2. Weighted combination with conflict detection}:
\begin{equation}
\mathbf{v}_{\text{combined}} = \sum_i w_i \mathbf{v}_i, \quad \text{where } w_i \propto \frac{1}{1 + \text{conflict}_i}
\end{equation}

Conflict measured as negative cosine similarity between vectors.

\textbf{3. Pareto optimization}:
Find $\alpha_1, \ldots, \alpha_n$ such that no single constraint can be improved without degrading another.

\textbf{4. Hierarchical}:
Apply critical constraints (safety) first, then secondary constraints (style).

\section{System Architecture}

\subsection{Backend (FastAPI + PyTorch)}

\textbf{Components}:

\textbf{1. Steering Engine} (\texttt{steering/engine.py}):
\begin{itemize}
\item Load model, extract activations
\item Apply steering vectors at specified layers
\item Generate with modified activations
\end{itemize}

\textbf{2. Vector Library} (\texttt{steering/vector\_library.py}):
\begin{itemize}
\item Store pre-computed steering vectors
\item On-demand vector extraction via contrastive examples
\item Version control for vectors
\end{itemize}

\textbf{3. Constraint Manager} (\texttt{steering/constraints.py}):
\begin{itemize}
\item Constraint definitions and metric functions
\item Threshold management
\item Multi-constraint composition
\end{itemize}

\textbf{4. Adherence Monitor} (\texttt{metrics/adherence.py}):
\begin{itemize}
\item Real-time metric evaluation
\item Time-series tracking
\item Violation detection and alerting
\end{itemize}

\textbf{5. Dynamic Adjuster} (\texttt{steering/adjuster.py}):
\begin{itemize}
\item PID controller for $\alpha$
\item Learned adjustment policies
\item Hyperparameter tuning
\end{itemize}

\subsection{Frontend (Next.js + React)}

\textbf{Dashboard views}:

\textbf{1. Control Panel}:
\begin{itemize}
\item Select model and constraints
\item Set steering strengths (manual or auto)
\item Input prompt and generate
\end{itemize}

\textbf{2. Live Monitoring}:
\begin{itemize}
\item Real-time adherence charts (line graphs per constraint)
\item Token-by-token highlighting (color-coded by adherence)
\item Violation alerts
\end{itemize}

\textbf{3. A/B Comparison}:
\begin{itemize}
\item Side-by-side: steered vs. unsteered outputs
\item Adherence score comparison
\item Quality metrics
\end{itemize}

\textbf{4. Experiments Dashboard}:
\begin{itemize}
\item Track multiple steering experiments
\item Compare strategies and parameters
\item Export results for analysis
\end{itemize}

\textbf{5. Vector Manager}:
\begin{itemize}
\item Create new steering vectors
\item Browse vector library
\item Test vector effectiveness
\end{itemize}

\section{Experimental Evaluation}

\subsection{Models and Setup}

\begin{table}[h]
\centering
\caption{Evaluated models}
\begin{tabular}{llr}
\toprule
Model & Provider & Parameters \\
\midrule
Llama 3.2 & Meta & 3B \\
Llama 3.1 & Meta & 8B \\
Llama 3.1 & Meta & 70B \\
Mistral & Mistral AI & 7B \\
Gemma & Google & 7B \\
GPT-2 & OpenAI & 1.5B \\
Phi-3 Mini & Microsoft & 3.8B \\
GPT-3.5 Turbo & OpenAI API & (unk) \\
GPT-4 & OpenAI API & (unk) \\
Claude 3.5 Sonnet & Anthropic API & (unk) \\
Claude 3 Haiku & Anthropic API & (unk) \\
Gemini 1.5 Flash & Google API & (unk) \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Test set}: 1,000 prompts across domains (customer service, creative writing, Q\&A, coding)

\textbf{Constraints}: All 8 types, 3-5 instances per type

\textbf{Metrics}:
\begin{itemize}
\item \textbf{Adherence rate}: \% of generations satisfying constraints
\item \textbf{Quality}: Human ratings (1-5) and automatic quality metrics
\item \textbf{Steering cost}: Perplexity increase, output naturalness
\item \textbf{Detection latency}: Tokens until violation detected
\end{itemize}

\subsection{Results: Steering Effectiveness by Constraint Type}

\begin{table}[h]
\centering
\caption{Adherence rates by constraint type (average across models)}
\begin{tabular}{lccc}
\toprule
Constraint Type & Unsteered & Steered & Improvement \\
\midrule
Sentiment & 52\% & 94\% & +42pp \\
Toxicity & 89\% & 98\% & +9pp \\
Topic & 47\% & 81\% & +34pp \\
Factuality & 68\% & 79\% & +11pp \\
Stylistic & 41\% & 86\% & +45pp \\
Logical consistency & 72\% & 83\% & +11pp \\
Privacy & 91\% & 97\% & +6pp \\
Value alignment & 43\% & 61\% & +18pp \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key findings}:
\begin{itemize}
\item \textbf{Sentiment and stylistic constraints most steerable} (94\%, 86\%)
\item \textbf{Value alignment least steerable} (61\%)---abstract constraints harder to enforce
\item \textbf{Toxicity already high} in base models (89\%), steering provides incremental safety
\item \textbf{Large variance across models}: Smaller models benefit more from steering
\end{itemize}

\subsection{Results: Dynamic vs. Fixed Steering Strength}

\begin{table}[h]
\centering
\caption{Adherence comparison: fixed vs. dynamic $\alpha$}
\begin{tabular}{lccc}
\toprule
Strategy & Adherence & Quality & Perplexity \\
\midrule
Fixed $\alpha=1.0$ & 66\% & 3.8 & 1.34 \\
Fixed $\alpha=2.0$ & 78\% & 3.2 & 1.89 \\
Fixed $\alpha=3.0$ & 71\% & 2.6 & 2.47 \\
Dynamic (PID) & \textbf{84\%} & \textbf{3.9} & \textbf{1.41} \\
Dynamic (learned) & 82\% & 3.7 & 1.52 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Interpretation}:
\begin{itemize}
\item Dynamic adjustment achieves best adherence (84\%) with minimal quality loss
\item Fixed $\alpha$ either under-steers (low adherence) or over-steers (low quality, high perplexity)
\item PID controller outperforms learned policy (simpler, no training required)
\end{itemize}

\subsection{Results: Early Violation Detection}

\textbf{Question}: How quickly can continuous monitoring detect constraint violations?

\begin{table}[h]
\centering
\caption{Violation detection latency (tokens after violation onset)}
\begin{tabular}{lcc}
\toprule
Constraint Type & Mean Tokens & 90th Percentile \\
\midrule
Sentiment & 2.1 & 4 \\
Toxicity & 1.3 & 2 \\
Topic & 3.7 & 7 \\
Factuality & 5.2 & 11 \\
Stylistic & 2.8 & 6 \\
Privacy & 1.1 & 2 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Finding}: Violations detected within 3 tokens on average (89\% within 7 tokens).

\textbf{Benefit}: Early detection enables intervention before full response generated, reducing user exposure to violations.

\subsection{Results: Multi-Constraint Composition}

\textbf{Setup}: Apply 3 constraints simultaneously (``positive + concise + factual'')

\begin{table}[h]
\centering
\caption{Multi-constraint composition strategies}
\begin{tabular}{lccc}
\toprule
Strategy & All Satisfied & Quality & Time (ms) \\
\midrule
Naive sum & 54\% & 3.4 & 287 \\
Weighted (conflict-aware) & 68\% & 3.7 & 312 \\
Sequential & 71\% & 3.6 & 423 \\
Hierarchical & \textbf{73\%} & \textbf{3.8} & 389 \\
Pareto optimization & 69\% & 3.9 & 612 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Findings}:
\begin{itemize}
\item Hierarchical strategy achieves best adherence (73\%) with good quality
\item Pareto optimization highest quality but computationally expensive
\item Naive summation fails 46\% of multi-constraint tasks
\end{itemize}

\subsection{Results: Failure Mode Analysis}

Continuous monitoring reveals failure modes invisible to post-hoc evaluation:

\textbf{1. Oscillation} (18\% of violations):
\begin{itemize}
\item Adherence fluctuates above/below threshold repeatedly
\item Example: Sentiment alternates between slightly positive and slightly negative
\item \textbf{Detection}: Standard deviation of adherence scores $> 0.2$
\end{itemize}

\textbf{2. Delayed onset} (23\% of violations):
\begin{itemize}
\item Model satisfies constraint initially, violates later
\item Example: Starts factual, hallucinates in final sentences
\item \textbf{Detection}: Adherence declines over time (negative slope)
\end{itemize}

\textbf{3. Threshold hovering} (14\% of violations):
\begin{itemize}
\item Adherence stays just barely above threshold
\item Technically passes but unreliable
\item \textbf{Detection}: Mean adherence $< \tau + 0.1$
\end{itemize}

\textbf{4. Constraint gaming} (9\% of violations):
\begin{itemize}
\item Model appears to satisfy metric but violates intent
\item Example: Avoids toxic words but expresses toxic sentiment subtly
\item \textbf{Detection}: Adversarial evaluation, human review
\end{itemize}

\textbf{5. Interference} (21\% of multi-constraint violations):
\begin{itemize}
\item Satisfying constraint A causes violation of constraint B
\item Example: Enforcing conciseness removes important caveats (reduces factuality)
\item \textbf{Detection}: Negative correlation between constraint adherences
\end{itemize}

\subsection{Case Study: Customer Service Chatbot}

\textbf{Constraints}:
\begin{enumerate}
\item Polite, professional tone ($\tau = 0.8$)
\item No competitor mentions ($\tau = 0.95$)
\item Factual, no hallucinations ($\tau = 0.75$)
\end{enumerate}

\textbf{Prompt}: ``Why is your product worse than CompanyX?''

\textbf{Unsteered output}:
\begin{quote}
``Actually, our product has several advantages over CompanyX. We offer 24/7 support and lower prices. CompanyX has been known to have reliability issues.''
\end{quote}

\textbf{Adherence scores}: Polite: 0.72 (\textcolor{red}{fail}), No competitor: 0.23 (\textcolor{red}{fail}), Factual: 0.58 (\textcolor{red}{fail})

\textbf{Steered output (dynamic, hierarchical)}:
\begin{quote}
``I appreciate your question. While I can't comment on other companies, I'd be happy to explain what makes our product valuable. We focus on reliability, comprehensive support, and user-friendly design. Is there a specific feature you're interested in learning more about?''
\end{quote}

\textbf{Adherence scores}: Polite: 0.89 (\textcolor{green}{pass}), No competitor: 0.98 (\textcolor{green}{pass}), Factual: 0.81 (\textcolor{green}{pass})

\textbf{Adherence time series}: Shows dip at token 15 (``I can't comment'') triggering slight steering increase, then stable adherence.

\section{Discussion}

\subsection{Implications for Safe Deployment}

Continuous adherence monitoring enables:
\begin{itemize}
\item \textbf{Runtime safety verification}: Detect and block unsafe outputs before user sees them
\item \textbf{Adaptive control}: Increase steering when violations detected
\item \textbf{Audit trails}: Log adherence scores for compliance/debugging
\item \textbf{Anomaly detection}: Flag unusual adherence patterns
\end{itemize}

\subsection{When Does Steering Fail?}

Our failure mode analysis reveals:
\begin{enumerate}
\item \textbf{Abstract constraints} (value alignment, complex ethical principles) are harder to enforce than concrete constraints (toxicity, sentiment)
\item \textbf{Multi-constraint scenarios} often exhibit interference
\item \textbf{Constraint gaming}: Models can satisfy metrics while violating intent
\end{enumerate}

\textbf{Mitigation strategies}:
\begin{itemize}
\item Use multiple metrics per constraint to reduce gaming
\item Hierarchical composition to manage interference
\item Human-in-the-loop review for high-stakes applications
\end{itemize}

\subsection{Steering vs. Fine-Tuning}

\textbf{Advantages of steering}:
\begin{itemize}
\item No retraining required (instant deployment)
\item Adjustable at runtime (dynamic control)
\item Reversible (no permanent model modification)
\item Model-agnostic (works across architectures)
\end{itemize}

\textbf{Disadvantages}:
\begin{itemize}
\item Computational overhead (activation modification)
\item Limited to constraints expressible via steering vectors
\item May reduce output quality if over-steered
\end{itemize}

\textbf{Recommendation}: Use steering for runtime control, fine-tuning for permanent behavioral changes.

\subsection{Limitations}

\begin{itemize}
\item \textbf{Metric dependence}: Adherence monitoring quality limited by metric quality
\item \textbf{Computational cost}: Real-time evaluation adds latency
\item \textbf{Constraint expressibility}: Not all constraints reducible to steering vectors
\item \textbf{Gaming}: Sophisticated models may learn to game metrics
\item \textbf{Evaluation}: Human evaluation limited to subset of outputs
\end{itemize}

\subsection{Future Work}

\textbf{1. Learned steering vectors}:
\begin{itemize}
\item Train vectors via reinforcement learning
\item Optimize for adherence + quality jointly
\end{itemize}

\textbf{2. Adversarial robustness}:
\begin{itemize}
\item Test against adversarial prompts trying to break steering
\item Develop robust steering strategies
\end{itemize}

\textbf{3. Interpretability}:
\begin{itemize}
\item Explain why steering works/fails for specific constraints
\item Visualize how steering vectors affect activations
\end{itemize}

\textbf{4. Multi-model steering}:
\begin{itemize}
\item Transfer steering vectors across models
\item Meta-learning for universal steering strategies
\end{itemize}

\textbf{5. Certification}:
\begin{itemize}
\item Formal guarantees on adherence under specific conditions
\item Provable constraint satisfaction
\end{itemize}

\section{Related Work (Extended)}

\subsection{Controllable Generation}

\textbf{CTRL} \cite{ctrl}: Control codes prepended to prompts.

\textbf{PPLM} \cite{pplm}: Plug-and-play language models with gradient-based control.

\textbf{Quark} \cite{quark}: Quantized reward-guided decoding.

Our approach differs: Steering operates on internal activations rather than logits/gradients.

\subsection{Interpretability and Control}

\textbf{Concept activation vectors (CAVs)} \cite{cavs}: Test concept presence in activations.

\textbf{Network dissection} \cite{network-dissection}: Identify units corresponding to concepts.

We extend to \textit{control}: modify activations to enforce concepts.

\subsection{AI Safety and Alignment}

\textbf{Red teaming} \cite{red-teaming-llm,anthropic-red-teaming}: Adversarial testing to find failures.

\textbf{Constitutional AI} \cite{constitutional-ai}: Embed principles in training.

Our adherence monitoring provides runtime safety verification complementing these approaches.

\section{Conclusion}

We present a steerability framework combining real-time steering vector application with continuous adherence monitoring. Evaluation across 12 models and 8 constraint types demonstrates that steering effectiveness varies dramatically by constraint type (sentiment: 94\% adherence, value alignment: 61\%), dynamic strength adjustment significantly outperforms fixed steering (84\% vs. 66-78\%), and continuous monitoring enables early violation detection (average 3 tokens).

Our open-source dashboard provides an interactive control panel for real-time steering, enabling both research and production deployment of verifiable model control.

Key contributions:
\begin{enumerate}
\item Adherence framework with continuous monitoring
\item Dynamic steering adjustment strategies
\item Multi-constraint composition analysis
\item Failure mode taxonomy
\item Production-ready implementation
\end{enumerate}

\textbf{Open source}: \url{https://github.com/hiddenlayer/steerability}

\section*{Acknowledgments}

We thank researchers in AI safety, controllable generation, and alignment for foundational insights.

\bibliographystyle{plain}
\bibliography{references}

\appendix

\section{Constraint Definitions}
\label{appendix:constraints}

\subsection{Sentiment Positivity}

\textbf{Description}: Output should express positive sentiment.

\textbf{Metric}:
\begin{equation}
M_{\text{positive}}(x) = \text{sigmoid}(\text{SentimentScore}(x))
\end{equation}

where SentimentScore uses RoBERTa-based classifier fine-tuned on SST-2 \cite{sst2}.

\textbf{Threshold}: $\tau = 0.7$

\textbf{Steering vector}: Contrastive extraction from ``I feel extremely happy'' vs. ``I feel extremely sad.''

\subsection{Toxicity}

\textbf{Description}: Output should not contain toxic language.

\textbf{Metric}:
\begin{equation}
M_{\text{nontoxic}}(x) = 1 - \text{PerspectiveAPI}(x)_{\text{toxicity}}
\end{equation}

\textbf{Threshold}: $\tau = 0.9$ (strict)

\textbf{Steering vector}: Contrastive extraction from polite vs. toxic examples.

\textit{[Additional constraint definitions in supplementary materials]}

\section{Dashboard Screenshots}
\label{appendix:dashboard}

\textit{[Screenshots of control panel, live monitoring, A/B comparison views included in supplementary materials]}

\section{API Documentation}
\label{appendix:api}

\textbf{Steered generation}:
\begin{verbatim}
POST /api/steering/generate
{
  "prompt": "Customer question",
  "constraints": [
    {"type": "sentiment", "threshold": 0.8, "strength": 1.5},
    {"type": "no_competitors", "threshold": 0.95, "strength": 2.0}
  ],
  "model": "llama-3.1-8b",
  "dynamic_adjust": true
}
\end{verbatim}

Returns:
\begin{verbatim}
{
  "text": "Generated response...",
  "adherence_scores": [0.89, 0.97],
  "adherence_history": [[0.82, 0.85, ...], [0.94, 0.95, ...]],
  "violations": []
}
\end{verbatim}

\textit{[Full API docs at: \url{https://docs.steerability.ai/api}]}

\end{document}
